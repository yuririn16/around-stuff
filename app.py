import streamlit as st
import mediapipe as mp
from mediapipe.tasks import python
from mediapipe.tasks.python import vision
import numpy as np
from PIL import Image, ImageOps, ImageDraw
import urllib.request
import os

# æ—¥æœ¬èªãƒ©ãƒ™ãƒ«è¾æ›¸
LABEL_MAP = {
    "person": "äººé–“", "bicycle": "è‡ªè»¢è»Š", "car": "è»Š", "motorcycle": "ãƒã‚¤ã‚¯",
    "bottle": "ãƒœãƒˆãƒ«", "cup": "ã‚³ãƒƒãƒ—", "chair": "æ¤…å­", "tv": "ãƒ†ãƒ¬ãƒ“",
    "laptop": "PC", "mouse": "ãƒã‚¦ã‚¹", "keyboard": "ã‚­ãƒ¼ãƒœãƒ¼ãƒ‰", "cell phone": "ã‚¹ãƒãƒ›"
}

st.set_page_config(page_title="AIã‚«ãƒ¡ãƒ©", layout="centered")
st.title("ğŸ¨ ã‚«ãƒ©ãƒ¼åˆ¥ãƒ»AIç‰©ä½“æ¤œå‡º")

# 1. ãƒ¢ãƒ‡ãƒ«æº–å‚™
model_path = "model.tflite"
model_url = "https://storage.googleapis.com/mediapipe-models/object_detector/efficientdet_lite0/float16/1/efficientdet_lite0.tflite"

@st.cache_resource
def load_model_file():
    if not os.path.exists(model_path):
        urllib.request.urlretrieve(model_url, model_path)
    return model_path

try:
    m_file = load_model_file()
except:
    st.error("ãƒ¢ãƒ‡ãƒ«ã®èª­ã¿è¾¼ã¿ã«å¤±æ•—ã—ã¾ã—ãŸ")

# 2. ã‚«ãƒ¡ãƒ©å…¥åŠ›
img_file = st.camera_input("æ’®å½±ã™ã‚‹")

if img_file is not None:
    # ç”»åƒæº–å‚™
    img = Image.open(img_file)
    img = ImageOps.exif_transpose(img)
    img_np = np.array(img).astype(np.uint8)
    mp_img = mp.Image(image_format=mp.ImageFormat.SRGB, data=img_np)

    # 3. AIã®è¨­å®š (è¡Œã‚’çŸ­ãåˆ†å‰²ã—ã¦ã‚¨ãƒ©ãƒ¼é˜²æ­¢)
    base_ops = python.BaseOptions(model_asset_path=m_file)
    options = vision.ObjectDetectorOptions(
        base_options=base_ops,
        score_threshold=0.3
    )

    # 4. å®Ÿè¡Œã¨è¡¨ç¤º
    try:
        with vision.ObjectDetector.create_from_options(options) as detector:
            res = detector.detect(mp_img)
            draw_img = img.copy()
            draw = ImageDraw.Draw(draw_img)
            
            # é®®ã‚„ã‹ãªè‰²ã®ãƒªã‚¹ãƒˆ
            COLORS = ["#FF3B30", "#4CD964", "#007AFF", "#FFCC00", "#FF9500", "#5856D6"]

            if res.detections:
                for i, det in enumerate(res.detections):
                    # è‰²ã®é¸æŠ
                    c_color = COLORS[i % len(COLORS)]
                    
                    # åº§æ¨™
                    b = det.bounding_box
                    rect = [b.origin_x, b.origin_y, b.origin_x + b.width, b.origin_y + b.height]
                    
                    # æç”» (æ )
                    draw.rectangle(rect, outline=c_color, width=8)
                    
                    # ãƒ©ãƒ™ãƒ«
                    cat = det.categories[0]
                    name = LABEL_MAP.get(cat.category_name, cat.category_name)
                    txt = f"{name} {int(cat.score*100)}%"
                    
                    # ãƒ©ãƒ™ãƒ«èƒŒæ™¯
                    draw.rectangle([rect[0], rect[1]-35, rect[0]+len(txt)*18, rect[1]], fill=c_color)
                    draw.text((rect[0]+5, rect[1]-30), txt, fill="white")
                
                st.image(draw_img, use_container_width=True)
                
                # ãƒ¬ãƒãƒ¼ãƒˆ
                st.subheader("ğŸ“Š æ¤œå‡ºçµæœ")
                for i, det in enumerate(res.detections):
                    cat = det.categories[0]
                    n = LABEL_MAP.get(cat.category_name, cat.category_name)
                    st.markdown(f"<span style='color:{COLORS[i%len(COLORS)]}'>â—</span> {n}", unsafe_allow_html=True)
                    st.progress(float(cat.score))
            else:
                st.image(img, use_container_width=True)
                st.info("ä½•ã‚‚æ¤œçŸ¥ã•ã‚Œã¾ã›ã‚“ã§ã—ãŸ")
    except Exception as e:
        st.error(f"å®Ÿè¡Œã‚¨ãƒ©ãƒ¼: {e}")
