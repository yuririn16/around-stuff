import streamlit as st
import mediapipe as mp
from mediapipe.tasks import python
from mediapipe.tasks.python import vision
import numpy as np
from PIL import Image, ImageOps
import urllib.request
import cv2
import os

# --- è¨­å®šã¨æ—¥æœ¬èªè¾æ›¸ ---
LABEL_MAP = {
    "person": "äººé–“", "bicycle": "è‡ªè»¢è»Š", "car": "è»Š", "motorcycle": "ãƒã‚¤ã‚¯",
    "airplane": "é£›è¡Œæ©Ÿ", "bus": "ãƒã‚¹", "train": "é›»è»Š", "truck": "ãƒˆãƒ©ãƒƒã‚¯",
    "boat": "èˆ¹", "traffic light": "ä¿¡å·æ©Ÿ", "stop sign": "ä¸€æ™‚åœæ­¢",
    "bench": "ãƒ™ãƒ³ãƒ", "bird": "é³¥", "cat": "çŒ«", "dog": "çŠ¬", "horse": "é¦¬",
    "sheep": "ç¾Š", "cow": "ç‰›", "elephant": "è±¡", "bear": "ã‚¯ãƒ", "zebra": "ã‚·ãƒã‚¦ãƒ",
    "giraffe": "ã‚­ãƒªãƒ³", "backpack": "ãƒªãƒ¥ãƒƒã‚¯", "umbrella": "å‚˜", "handbag": "ãƒãƒ³ãƒ‰ãƒãƒƒã‚°",
    "tie": "ãƒã‚¯ã‚¿ã‚¤", "suitcase": "ã‚¹ãƒ¼ãƒ„ã‚±ãƒ¼ã‚¹", "frisbee": "ãƒ•ãƒªã‚¹ãƒ“ãƒ¼", "skis": "ã‚¹ã‚­ãƒ¼æ¿",
    "snowboard": "ã‚¹ãƒãƒ¼ãƒœãƒ¼ãƒ‰", "sports ball": "ãƒœãƒ¼ãƒ«", "kite": "å‡§", "baseball bat": "ãƒãƒƒãƒˆ",
    "baseball glove": "ã‚°ãƒ­ãƒ¼ãƒ–", "skateboard": "ã‚¹ã‚±ãƒœãƒ¼", "surfboard": "ã‚µãƒ¼ãƒ•ãƒœãƒ¼ãƒ‰",
    "tennis racket": "ãƒ©ã‚±ãƒƒãƒˆ", "bottle": "ãƒœãƒˆãƒ«", "wine glass": "ã‚°ãƒ©ã‚¹", "cup": "ã‚³ãƒƒãƒ—",
    "fork": "ãƒ•ã‚©ãƒ¼ã‚¯", "knife": "ãƒŠã‚¤ãƒ•", "spoon": "ã‚¹ãƒ—ãƒ¼ãƒ³", "bowl": "ãƒœã‚¦ãƒ«",
    "banana": "ãƒãƒŠãƒŠ", "apple": "ã‚Šã‚“ã”", "sandwich": "ã‚µãƒ³ãƒ‰ã‚¤ãƒƒãƒ", "orange": "ã‚ªãƒ¬ãƒ³ã‚¸",
    "broccoli": "ãƒ–ãƒ­ãƒƒã‚³ãƒªãƒ¼", "carrot": "ã«ã‚“ã˜ã‚“", "hot dog": "ãƒ›ãƒƒãƒˆãƒ‰ãƒƒã‚°", "pizza": "ãƒ”ã‚¶",
    "donut": "ãƒ‰ãƒ¼ãƒŠãƒ„", "cake": "ã‚±ãƒ¼ã‚­", "chair": "æ¤…å­", "couch": "ã‚½ãƒ•ã‚¡",
    "potted plant": "è¦³è‘‰æ¤ç‰©", "bed": "ãƒ™ãƒƒãƒ‰", "dining table": "æœº", "toilet": "ãƒˆã‚¤ãƒ¬",
    "tv": "ãƒ†ãƒ¬ãƒ“", "laptop": "PC", "mouse": "ãƒã‚¦ã‚¹", "remote": "ãƒªãƒ¢ã‚³ãƒ³",
    "keyboard": "ã‚­ãƒ¼ãƒœãƒ¼ãƒ‰", "cell phone": "ã‚¹ãƒãƒ›", "microwave": "é›»å­ãƒ¬ãƒ³ã‚¸",
    "oven": "ã‚ªãƒ¼ãƒ–ãƒ³", "toaster": "ãƒˆãƒ¼ã‚¹ã‚¿ãƒ¼", "sink": "ã‚·ãƒ³ã‚¯", "refrigerator": "å†·è”µåº«",
    "book": "æœ¬", "clock": "æ™‚è¨ˆ", "vase": "èŠ±ç“¶", "scissors": "ãƒã‚µãƒŸ",
    "teddy bear": "ã¬ã„ãã‚‹ã¿", "hair drier": "ãƒ‰ãƒ©ã‚¤ãƒ¤ãƒ¼", "toothbrush": "æ­¯ãƒ–ãƒ©ã‚·"
}

st.set_page_config(page_title="AIç‰©ä½“æ¤œå‡ºã‚«ãƒ¡ãƒ©", layout="centered")
st.title("ğŸš€ è¶…é«˜æ€§èƒ½ãƒ»AIç‰©ä½“æ¤œå‡ºã‚«ãƒ¡ãƒ©")

# --- ã‚µã‚¤ãƒ‰ãƒãƒ¼è¨­å®š ---
st.sidebar.header("ğŸ›  ã‚¢ãƒ—ãƒªè¨­å®š")
score_threshold = st.sidebar.slider("æ¤œçŸ¥ã®å³ã—ã•ï¼ˆã—ãã„å€¤ï¼‰", 0.0, 1.0, 0.4, 0.05)
max_results = st.sidebar.slider("æœ€å¤§æ¤œçŸ¥æ•°", 1, 10, 5)

# --- ãƒ¢ãƒ‡ãƒ«æº–å‚™ ---
model_path = "model.tflite"
model_url = "https://storage.googleapis.com/mediapipe-models/object_detector/efficientdet_lite0/float16/1/efficientdet_lite0.tflite"

@st.cache_resource
def load_model_file():
    if not os.path.exists(model_path):
        with st.spinner("AIãƒ¢ãƒ‡ãƒ«ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ä¸­..."):
            urllib.request.urlretrieve(model_url, model_path)
    return model_path

model_file = load_model_file()

# --- ãƒ¡ã‚¤ãƒ³å‡¦ç† ---
img_file = st.camera_input("ã‚«ãƒ¡ãƒ©ã§æ’®å½±")

if img_file is not None:
    image = Image.open(img_file)
    image = ImageOps.exif_transpose(image)
    image_np = np.array(image).astype(np.uint8)
    
    # æç”»ç”¨
    output_image = cv2.cvtColor(image_np, cv2.COLOR_RGB2BGR)
    mp_image = mp.Image(image_format=mp.ImageFormat.SRGB, data=image_np)

    options = vision.ObjectDetectorOptions(
        base_options=python.BaseOptions(model_asset_path=model_file),
        score_threshold=score_threshold,
        max_results=max_results
    )

    try:
        with vision.ObjectDetector.create_from_options(options) as detector:
            detection_result = detector.detect(mp_image)

            if detection_result.detections:
                colors = [(0, 255, 0), (255, 165, 0), (0, 191, 255), (255, 0, 255), (255, 255, 0)]
                
                # çµæœã‚’ä¿å­˜ã™ã‚‹ãƒªã‚¹ãƒˆ
                found_items = []

                for i, detection in enumerate(detection_result.detections):
                    color = colors[i % len(colors)]
                    bbox = detection.bounding_box
                    x, y, w, h = int(bbox.origin_x), int(bbox.origin_y), int(bbox.width), int(bbox.height)
                    
                    # æ ã®æç”»
                    cv2.rectangle(output_image, (x, y), (x + w, y + h), color, 4)
                    
                    # ãƒ©ãƒ™ãƒ«ã®æ—¥æœ¬èªåŒ–
                    category = detection.categories[0]
                    eng_name = category.category_name
                    jp_name = LABEL_MAP.get(eng_name, eng_name)
                    score_int = int(category.score * 100)
                    
                    label = f"{jp_name} ({score_int}%)"
                    found_items.append((jp_name, category.score))

                    # ãƒ†ã‚­ã‚¹ãƒˆèƒŒæ™¯ã‚’æç”»
                    (tw, th), _ = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, 0.8, 2)
                    text_y = y - 10 if y - 10 > th else y + th + 10
                    cv2.rectangle(output_image, (x, text_y - th - 5), (x + tw, text_y + 5), color, -1)
                    cv2.putText(output_image, label, (x, text_y), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (255, 255, 255), 2)
                
                # ç”»åƒè¡¨ç¤º
                final_image = cv2.cvtColor(output_image, cv2.COLOR_BGR2RGB)
                st.image(final_image, use_container_width=True)

                # ãƒ¬ãƒãƒ¼ãƒˆè¡¨ç¤º
                st.subheader("ğŸ“Š æ¤œå‡ºãƒ¬ãƒãƒ¼ãƒˆ")
                for name, score in found_items:
                    st.write(f"**{name}**")
                    st.progress(float(score))
            else:
                st.image(image_np, use_container_width=True)
                st.warning("ä½•ã‚‚æ¤œçŸ¥ã•ã‚Œã¾ã›ã‚“ã§ã—ãŸã€‚ã—ãã„å€¤ã‚’ä¸‹ã’ã‚‹ã‹ã€ã‚‚ã£ã¨è¿‘ã¥ã‘ã¦ã¿ã¦ãã ã•ã„ã€‚")
                
    except Exception as e:
        st.error(f"ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
