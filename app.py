import streamlit as st
import mediapipe as mp
from mediapipe.tasks import python
from mediapipe.tasks.python import vision
import numpy as np
from PIL import Image, ImageOps
import urllib.request
import cv2
import os

st.title("ç‰©ä½“æ¤œå‡ºã‚«ãƒ¡ãƒ©ï¼ˆãƒªã‚¹ãƒˆè¡¨ç¤ºç‰ˆï¼‰")

# 1. ãƒ¢ãƒ‡ãƒ«æº–å‚™
model_path = "model.tflite"
model_url = "https://storage.googleapis.com/mediapipe-models/object_detector/efficientdet_lite0/float16/1/efficientdet_lite0.tflite"

@st.cache_resource
def load_model_file():
    if not os.path.exists(model_path):
        with st.spinner("AIãƒ¢ãƒ‡ãƒ«ã‚’æº–å‚™ä¸­..."):
            urllib.request.urlretrieve(model_url, model_path)
    return model_path

try:
    model_file = load_model_file()
except Exception as e:
    st.error(f"ãƒ¢ãƒ‡ãƒ«ã®æº–å‚™ã‚¨ãƒ©ãƒ¼: {e}")

# 2. ã‚«ãƒ¡ãƒ©å…¥åŠ›
img_file = st.camera_input("å†™çœŸã‚’æ’®ã‚‹")

if img_file is not None:
    image = Image.open(img_file)
    image = ImageOps.exif_transpose(image)
    image_np = np.array(image).astype(np.uint8)
    
    # æç”»ç”¨ç”»åƒã®ä½œæˆ
    output_image = cv2.cvtColor(image_np, cv2.COLOR_RGB2BGR)
    mp_image = mp.Image(image_format=mp.ImageFormat.SRGB, data=image_np)

    # 3. æ¤œå‡ºå™¨ã®è¨­å®š
    base_options = python.BaseOptions(model_asset_path=model_file)
    options = vision.ObjectDetectorOptions(
        base_options=base_options,
        score_threshold=0.2,
        max_results=10
    )

    # 4. å®Ÿè¡Œã¨è¡¨ç¤º
    try:
        with vision.ObjectDetector.create_from_options(options) as detector:
            result = detector.detect(mp_image)

            if result.detections:
                colors = [(0, 255, 0), (255, 0, 0), (0, 0, 255), (0, 255, 255)]
                # ãƒªã‚¹ãƒˆç”¨ã®ãƒ‡ãƒ¼ã‚¿ã‚’æºœã‚ã‚‹å¤‰æ•°
                found_items = []

                for i, detection in enumerate(result.detections):
                    # æ ã¨ãƒ©ãƒ™ãƒ«ã®æç”»
                    color = colors[i % len(colors)]
                    box = detection.bounding_box
                    x, y, w, h = int(box.origin_x), int(box.origin_y), int(box.width), int(box.height)
                    cv2.rectangle(output_image, (x, y), (x + w, y + h), color, 3)
                    
                    cat = detection.categories[0]
                    label = f"{cat.category_name} {int(cat.score*100)}%"
                    cv2.putText(output_image, label, (x, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 1, color, 2)
                    
                    # --- ãƒªã‚¹ãƒˆè¡¨ç¤ºç”¨ã«ãƒ‡ãƒ¼ã‚¿ã‚’è¿½åŠ  ---
                    found_items.append({
                        "name": cat.category_name,
                        "score": int(cat.score * 100)
                    })

                # åŠ å·¥ã—ãŸç”»åƒã®è¡¨ç¤º
                final_img = cv2.cvtColor(output_image, cv2.COLOR_BGR2RGB)
                st.image(final_img, caption="æ¤œå‡ºæˆåŠŸ", use_container_width=True)

                # --- ç”»é¢ä¸‹éƒ¨ã®ãƒªã‚¹ãƒˆè¡¨ç¤º ---
                st.write("---")
                st.subheader("ğŸ“‹ æ¤œå‡ºã•ã‚ŒãŸç‰©ä½“ã®ãƒªã‚¹ãƒˆ")
                for item in found_items:
                    st.write(f"âœ… **{item['name']}** (ç¢ºä¿¡åº¦: {item['score']}%)")
                
                st.success(f"åˆè¨ˆ {len(found_items)} å€‹ã®ç‰©ä½“ãŒè¦‹ã¤ã‹ã‚Šã¾ã—ãŸ")

            else:
                st.image(image_np, caption="ä½•ã‚‚è¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ")
                st.info("æ˜ã‚‹ã„å ´æ‰€ã§æ’®ã‚Šç›´ã—ã¦ã¿ã¦ãã ã•ã„ã€‚")

    except Exception as e:
        st.error(f"AIå®Ÿè¡Œã‚¨ãƒ©ãƒ¼: {e}")
