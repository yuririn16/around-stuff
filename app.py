import streamlit as st
import mediapipe as mp
from mediapipe.tasks import python
from mediapipe.tasks.python import vision
import numpy as np
from PIL import Image, ImageOps, ImageDraw, ImageFont
import urllib.request
import os

# --- è¨­å®šã¨æ—¥æœ¬èªè¾æ›¸ ---
LABEL_MAP = {
    "person": "äººé–“", "bicycle": "è‡ªè»¢è»Š", "car": "è»Š", "motorcycle": "ãƒã‚¤ã‚¯",
    "airplane": "é£›è¡Œæ©Ÿ", "bus": "ãƒã‚¹", "train": "é›»è»Š", "truck": "ãƒˆãƒ©ãƒƒã‚¯",
    "bottle": "ãƒœãƒˆãƒ«", "wine glass": "ã‚°ãƒ©ã‚¹", "cup": "ã‚³ãƒƒãƒ—", "fork": "ãƒ•ã‚©ãƒ¼ã‚¯",
    "knife": "ãƒŠã‚¤ãƒ•", "spoon": "ã‚¹ãƒ—ãƒ¼ãƒ³", "bowl": "ãƒœã‚¦ãƒ«", "banana": "ãƒãƒŠãƒŠ",
    "apple": "ã‚Šã‚“ã”", "chair": "æ¤…å­", "couch": "ã‚½ãƒ•ã‚¡", "potted plant": "è¦³è‘‰æ¤ç‰©",
    "tv": "ãƒ†ãƒ¬ãƒ“", "laptop": "PC", "mouse": "ãƒã‚¦ã‚¹", "remote": "ãƒªãƒ¢ã‚³ãƒ³",
    "keyboard": "ã‚­ãƒ¼ãƒœãƒ¼ãƒ‰", "cell phone": "ã‚¹ãƒãƒ›", "book": "æœ¬", "clock": "æ™‚è¨ˆ"
}

st.set_page_config(page_title="AIç‰©ä½“æ¤œå‡ºã‚«ãƒ¡ãƒ©", layout="centered")
st.title("ğŸš€ å®‰å®šç‰ˆãƒ»AIç‰©ä½“æ¤œå‡ºã‚«ãƒ¡ãƒ©")

# --- ã‚µã‚¤ãƒ‰ãƒãƒ¼è¨­å®š ---
st.sidebar.header("ğŸ›  ã‚¢ãƒ—ãƒªè¨­å®š")
score_threshold = st.sidebar.slider("æ¤œçŸ¥ã®å³ã—ã•", 0.1, 1.0, 0.3, 0.05)

# --- ãƒ¢ãƒ‡ãƒ«æº–å‚™ ---
model_path = "model.tflite"
model_url = "https://storage.googleapis.com/mediapipe-models/object_detector/efficientdet_lite0/float16/1/efficientdet_lite0.tflite"

@st.cache_resource
def load_model_file():
    if not os.path.exists(model_path):
        urllib.request.urlretrieve(model_url, model_path)
    return model_path

model_file = load_model_file()

# --- ãƒ¡ã‚¤ãƒ³å‡¦ç† ---
img_file = st.camera_input("ã‚«ãƒ¡ãƒ©ã§æ’®å½±")

if img_file is not None:
    # 1. ç”»åƒã®èª­ã¿è¾¼ã¿ã¨å‘ãã®è£œæ­£
    image = Image.open(img_file)
    image = ImageOps.exif_transpose(image)
    
    # 2. AIç”¨ã®ç”»åƒãƒ‡ãƒ¼ã‚¿(numpy)ã‚’æº–å‚™
    # ã“ã“ã‚’ç¢ºå®Ÿã« uint8 å‹ã«ã™ã‚‹ã“ã¨ã§æ¤œçŸ¥æ¼ã‚Œã‚’é˜²ãã¾ã™
    image_np = np.array(image).astype(np.uint8)
    mp_image = mp.Image(image_format=mp.ImageFormat.SRGB, data=image_np)

    # 3. ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆæ¤œå‡ºã®è¨­å®š
    base_options = python.BaseOptions(model_asset_path=model_file)
    options = vision.ObjectDetectorOptions(
        base_options=base_options,
        score_threshold=score_threshold,
    )

    try:
        with vision.ObjectDetector.create_from_options(options) as detector:
            detection_result = detector.detect(mp_image)

            # 4. æç”»å‡¦ç† (Pillowã‚’ä½¿ç”¨)
            draw_image = image.copy()
            draw = ImageDraw.Draw(draw_image)
            
            # ãƒ•ã‚©ãƒ³ãƒˆèª­ã¿è¾¼ã¿ (æ—¥æœ¬èªãŒå‡ºãªã„å ´åˆã¯ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ)
            font = ImageFont.load_default()

            if detection_result.detections:
                colors = ["#00FF00", "#FF4B4B", "#1C83E1", "#FFD700", "#FF00FF"]
                
                for i, detection in enumerate(detection_result.detections):
                    color = colors[i % len(colors)]
                    bbox = detection.bounding_box
